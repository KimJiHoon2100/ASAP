{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 265s 5ms/step - loss: 0.9841 - acc: 0.6649 - val_loss: 0.1537 - val_acc: 0.9525\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.2450 - acc: 0.9246 - val_loss: 0.0989 - val_acc: 0.9687\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 191s 4ms/step - loss: 0.1726 - acc: 0.9461 - val_loss: 0.0738 - val_acc: 0.9778\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 198s 4ms/step - loss: 0.1422 - acc: 0.9563 - val_loss: 0.0619 - val_acc: 0.9820\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 191s 4ms/step - loss: 0.1229 - acc: 0.9621 - val_loss: 0.0580 - val_acc: 0.9830\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.1075 - acc: 0.9672 - val_loss: 0.0524 - val_acc: 0.9844\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 202s 4ms/step - loss: 0.0971 - acc: 0.9699 - val_loss: 0.0466 - val_acc: 0.9866\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 190s 4ms/step - loss: 0.0902 - acc: 0.9728 - val_loss: 0.0453 - val_acc: 0.9867\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 185s 4ms/step - loss: 0.0799 - acc: 0.9752 - val_loss: 0.0425 - val_acc: 0.9873\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0778 - acc: 0.9757 - val_loss: 0.0398 - val_acc: 0.9876\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 176s 4ms/step - loss: 0.0694 - acc: 0.9785 - val_loss: 0.0417 - val_acc: 0.9875\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 174s 3ms/step - loss: 0.0664 - acc: 0.9788 - val_loss: 0.0375 - val_acc: 0.9879\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 175s 4ms/step - loss: 0.0641 - acc: 0.9804 - val_loss: 0.0349 - val_acc: 0.9901\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 181s 4ms/step - loss: 0.0611 - acc: 0.9814 - val_loss: 0.0367 - val_acc: 0.9893\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0577 - acc: 0.9819 - val_loss: 0.0336 - val_acc: 0.9894\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 195s 4ms/step - loss: 0.0542 - acc: 0.9830 - val_loss: 0.0337 - val_acc: 0.9902\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.0535 - acc: 0.9837 - val_loss: 0.0324 - val_acc: 0.9904\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 203s 4ms/step - loss: 0.0495 - acc: 0.9843 - val_loss: 0.0323 - val_acc: 0.9905\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0487 - acc: 0.9847 - val_loss: 0.0305 - val_acc: 0.9914\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 193s 4ms/step - loss: 0.0478 - acc: 0.9851 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 193s 4ms/step - loss: 0.0464 - acc: 0.9852 - val_loss: 0.0312 - val_acc: 0.9909\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 204s 4ms/step - loss: 0.0444 - acc: 0.9861 - val_loss: 0.0336 - val_acc: 0.9898\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0442 - acc: 0.9860 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 216s 4ms/step - loss: 0.0427 - acc: 0.9864 - val_loss: 0.0289 - val_acc: 0.9913\n",
      "Epoch 25/30\n",
      "45248/50000 [==========================>...] - ETA: 18s - loss: 0.0423 - acc: 0.9863"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "width = 28\n",
    "height = 28\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "\n",
    "# 훈련셋과 시험셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, width, height, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, width, height, 1).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "x_val = x_train[50000:]\n",
    "y_val = y_train[50000:]\n",
    "x_train = x_train[:50000]\n",
    "y_train = y_train[:50000]\n",
    "\n",
    "# 데이터셋 전처리 : one-hot 인코딩\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_val = np_utils.to_categorical(y_val)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 0.5])\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylim([0.8, 1.0])\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "cnt = 0\n",
    "i = 0\n",
    "\n",
    "while cnt < (plt_row*plt_col):\n",
    "    \n",
    "    if np.argmax(y_test[i]) == np.argmax(yhat_test[i]):\n",
    "        i += 1\n",
    "        continue\n",
    "    \n",
    "    sub_plt = axarr[cnt//plt_row, cnt%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt_title = 'R: ' + str(np.argmax(y_test[i])) + ' P: ' + str(np.argmax(yhat_test[i]))\n",
    "    sub_plt.set_title(sub_plt_title)\n",
    "\n",
    "    i += 1    \n",
    "    cnt += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
